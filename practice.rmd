---
title: "practical"
output: html_document
---

## Practical Machine Learning Assignment
#Coursera Data Science Specialization
#Practical Machining Learning Module
#Project Assignment

# Load required packages for analysis
library(caret)
library(rpart)
library(ggplot2)
library(corrplot)
library(randomForest)
library(rattle)

training_raw <- read.csv("pml-training.csv")[,-1]
testing <- read.csv("pml-testing.csv")[,-1]
# check dimension of the training and test dataset
dim(training_raw)

dim(testing)

# Clean data

# remove predictors that have many missing/NA values or non-unique values
NZV <- nearZeroVar(training_raw)
training <- training_raw[, -NZV]
testing <- testing[, -NZV]

# remove cases that have many missing/NA values
NaValues <- sapply(training, function(x) mean(is.na(x))) > 0.9
training <- training[, NaValues == "FALSE"]
testing <- testing[, NaValues == "FALSE"]

# remove id and time variables
training <- training[,-c(1:5)]
testing <- testing[,-c(1:5)]

# check dimension of the cleaned up dataset
dim(training)

dim(testing)

# take a look at the training dataset
head(training)
# Prepare data partition, for later validation
inTrain <- createDataPartition(y= training$classe, p = 0.7, list = FALSE)
training <- training[inTrain, ]
crossvalidation <- training[-inTrain, ]
# Now we can train our models given the preprocess with PCA
# decision trees
model_tree <- train(classe~., data = training, method = "rpart")
# print result of model prediction on original training and crossvalidation dataset
predict_training_tree <- predict(model_tree, training)
confusionmatrix_training_tree <- confusionMatrix(predict_training_tree, training$classe)

predict_crossvalidation_tree <- predict(model_tree, crossvalidation)
confusionmatrix_cv_tree <- confusionMatrix(predict_crossvalidation_tree, crossvalidation$classe)

print(confusionmatrix_cv_tree)

# random forest
model_rf <- train(classe~., data = training, method = "rf")
# print result of model prediction on original training and crossvalidation dataset
predict_training_rf <- predict(model_rf, training)
confusionmatrix_training_rf <- confusionMatrix(predict_training_rf, training$classe)

predict_crossvalidation_rf <- predict(model_rf, crossvalidation)
confusionmatrix_cv_rf <- confusionMatrix(predict_crossvalidation_rf, crossvalidation$classe)

print(confusionmatrix_cv_rf)

 Conclusion
The confusionmatrix showed that the accuracy of the random forest models is better than the decision tree model. Therefore, we used this model to predict on the testing dataset.

# Predict on testing dataset
predict_testing <- predict(model_rf, testing)
predict_testing

# Appendix
# explore the remianing predictors
# check the factor variables
predictor_factor <- which(sapply(training, class) == "factor")
# explore correlation between predictors
predictor_cor <- abs(cor(training[,-predictor_factor]))
# turn lower tri to 0
predictor_cor[lower.tri(predictor_cor, diag = TRUE)] <- 0
# visualize result
corrplot(predictor_cor, method  = "color", type = "upper", cl.lim = c(0,1), tl.col = rgb(0, 0, 0))

# find highly correlated predictors
which(predictor_cor > 0.8, arr.ind = TRUE)
